{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general imports needed by functions\n",
    "import errno    \n",
    "import os\n",
    "\n",
    "# import python scientific libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import needed keras objects into current namespace\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting visual style and parameters for all plotted figures\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid') # use seaborn style to improve visual presentation\n",
    "sns.set_context('notebook')\n",
    "plt.rcParams['figure.figsize'] = (12.0 , 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3516041434571516116\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2393453564272176661\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check which devices tensorflow has recognized and is using\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Advanced deep-learning best practices\n",
    "\n",
    "This notebook explores a number of powerful tools\n",
    "that are useful when you get beyond building\n",
    "straightforward deep networks for classic\n",
    "regression or classification problems.\n",
    "\n",
    "## 7.1 Going beyond the Sequential model: the Keras functional API\n",
    "\n",
    "We have mostly been using the Keras `Sequential`\n",
    "model to this point in the class/textbook.\n",
    "This model makes (simplifying) assumption that the\n",
    "deep network has exactly one input (tensor) and\n",
    "also exactly one output (tensor).\n",
    "\n",
    "Some use cases and network designs require more\n",
    "flexibility.  We may have several independent\n",
    "inputs and/or need to make several predictions\n",
    "in parallel for a given task.  Further, some networks\n",
    "have internal branching between layers that make\n",
    "them look like directed graphys of layers rather\n",
    "than linear stacks of layers.\n",
    "\n",
    "For *multimodal* inputs, we want to merge data\n",
    "coming from different input sources. We often want\n",
    "to process such data using different types of\n",
    "neural networks, before merging the extracted\n",
    "features for our task.\n",
    "\n",
    "If we had multiple inputs, a naive approach would be\n",
    "to train multiple netwoks separately, and then do\n",
    "a weighted average of their predictions.  But this\n",
    "is usually suboptimal, because the information \n",
    "extracted by the models may be redundant.  \n",
    "\n",
    "A better way is to *jointly* learn a more accurate\n",
    "model of the data by using a single model that\n",
    "can see all available input modalities\n",
    "simultaneously.\n",
    "\n",
    "Similarly some tasks need to predict multiple\n",
    "target attributes.  Again we could train\n",
    "separate networks.  But the input data nor the\n",
    "output targets are usually statistically independent,\n",
    "and thus we can usually do better by building a\n",
    "single model that learns the multiple outputs\n",
    "jointly.\n",
    "\n",
    "Finally, more recent neural network architectures\n",
    "are beginning to require nonlinear network topology:\n",
    "networks structures as directed acylic graphs. \n",
    "This are **acylic**, they are different from the \n",
    "recurrent network layers we discussed previously.\n",
    "But the graphs of the layers are more complex than\n",
    "the linear sequence of sequential layers we have\n",
    "mainly seen to this point.\n",
    "\n",
    "The **Inception** family of networks, and the\n",
    "**ResNet** architectures are examples of these\n",
    "more complex processing networks.\n",
    "\n",
    "For these three important use cases -- multi-input,\n",
    "multi-output, and more complex acylic directed graph-like\n",
    "models  -- we cannot use Keras' simple `Sequential`\n",
    "model class.  \n",
    "\n",
    "Keras as a more flexible interface: the *functional API*.\n",
    "The functional API uses concepts from functional\n",
    "programming, and allows for more flexible specifications\n",
    "of networks like these we just introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Introduction to the functional API\n",
    "\n",
    "In the Keras functional API you directly manipulate\n",
    "tensors, and you use layers as *functions* that take\n",
    "tensors and return tensors (hence, the name\n",
    "*functional API):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(None, 32)\n"
     ]
    }
   ],
   "source": [
    "# A tensor\n",
    "input_tensor = Input(shape=(32,))\n",
    "\n",
    "# because using TensorFlow back end, this is actual\n",
    "# a tensor object from TensorFlow\n",
    "print(type(input_tensor))\n",
    "# notice shape is 2D, so we expect (samples, features)\n",
    "# in shaped tensors for this example\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "# a layer is a function\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "print(type(dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(None, 32)\n"
     ]
    }
   ],
   "source": [
    "# a layer may be called on a tensor, and it returns\n",
    "# a tensor\n",
    "output_tensor = dense(input_tensor)\n",
    "print(type(output_tensor))\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a minimal example that shows\n",
    "side by side a simple `Sequential` model\n",
    "and its equivalent in the functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first using Sequential model\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building the equivalent using functional API\n",
    "input_tensor = Input(shape=(64,))\n",
    "first_layer_function = layers.Dense(32, activation='relu')\n",
    "x = first_layer_function(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# the Model class turns an input tensor and output\n",
    "# tensor into a model\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, there are hooks so that\n",
    "Keras can retrieve every layer that connects\n",
    "the provided `input_tensor` to the `output_tensor`.\n",
    "This create a graph-like data structure -\n",
    "a `Model`.  It is an error to provide an\n",
    "`output_tensor` that was not derived by repeatedly\n",
    "transforming from the `input_tensor`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(None, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b18fa274e6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 241\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                                          \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                                          \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1512\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(None, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error means that Keras couldn't reach the\n",
    "output tensor from the provided input tensor.\n",
    "\n",
    "Once you create the network and encapsulate into\n",
    "a `Model` in eras, compiling, training and \n",
    "evaluating such a `Model` instance is done in\n",
    "exactly the same way as we have been doing it for\n",
    "the `Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 416us/step - loss: 12.3042\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 13.7532\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 16.0463\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 18.7946\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 22.2573\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 25.9515\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 29.9994\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 34.9266\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 39.9915\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 45.4285\n",
      "1000/1000 [==============================] - 0s 77us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# gnerates dummy NumPy data to train on\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# train the model for 10 epochs\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "# evalute the model\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Multi-Input model\n",
    "\n",
    "In this section we have an example of building\n",
    "a model with multiple inputs.  Typically\n",
    "such models at some point merge the different\n",
    "input branches using a layer that can combine\n",
    "several tensors: by adding them, or concatenating them,\n",
    "or so on.  This is done with things like\n",
    "`keras.layers.add` and `keras.layers.concatenate`.\n",
    "\n",
    "A typical question-answering model has two inputs:\n",
    "a natural-language question and a text snippet\n",
    "(such as a news article) providing information\n",
    "to be used for answering the question.  The model\n",
    "then must produce an answer: in the simplest possible\n",
    "setup, this is a one-word answer obtained via\n",
    "softmax over some predefined vocabulary.\n",
    "\n",
    "Following is an example of how we can build such\n",
    "a model using the Keras functional API.\n",
    "We use two independent branches for the input,\n",
    "LSTM's that learn the different sequences.  These\n",
    "representations are concatenated and a softmax\n",
    "classifier is added on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# the text input is a variable length sequence\n",
    "# of integers, note we name the input tensor\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "# embeds the inputs into a sequence of vectors of\n",
    "# size 64\n",
    "embedded_text = layers.Embedding(text_vocabulary_size,\n",
    "                                 64)(text_input)\n",
    "\n",
    "# encodes the vectors in a single vector via an LSTM\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# same process for the question\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "\n",
    "embedded_question = layers.Embedding(question_vocabulary_size,\n",
    "                                     32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# concatenates the encoded question and encoded text\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],\n",
    "                                  axis=-1)\n",
    "\n",
    "# adds a softmax classifier on top\n",
    "answer = layers.Dense(answer_vocabulary_size,\n",
    "                      activation='softmax')(concatenated)\n",
    "\n",
    "# at model instantiation, you specify the two inputs\n",
    "# and the output\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 16)           3136        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how do you train this two-input model?  There are\n",
    "two possible APIs: you can feed the model a list\n",
    "of Numpy arrays as inputs, or you can feed it a\n",
    "dictionary that maps input names to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# generates dummy numpy data\n",
    "# notice that the input text is integers from 0 to 100\n",
    "# and is shaped to be padded to 100 (dummy) words\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "# also dummy questions, again padded to 100 words\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                             size=(num_samples, max_length))\n",
    "\n",
    "# answers are one-hot encoded, not integers\n",
    "answers = np.random.randint(0, 1,\n",
    "                            size=(num_samples, answer_vocabulary_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "(1000, 100)\n",
      "(1000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(text.shape)\n",
    "print(question.shape)\n",
    "print(answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dash/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0000e+00 - acc: 0.0020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa400e5750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1, as a list of numpy arrays for inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa80075fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2: fitting using a dictionary of inputs\n",
    "# only works if input functions/layers are named\n",
    "model.fit({'text': text, 'question': question}, \n",
    "          answers,\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Multi-output models\n",
    "\n",
    "In the same way, you can use the functional API\n",
    "to build models with multiple outputs\n",
    "(or multiple *heads*).  A simple example is a network\n",
    "that attempts to simultaneously predict different\n",
    "properties of the data, such as social media\n",
    "posts as inputs and tries to predict several attributes\n",
    "of the poster, like age, gender and income level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# note that the output layers are given names\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',\n",
    "                                 name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', \n",
    "                                 name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, \n",
    "              [age_prediction, income_prediction, gender_prediction])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model with multiple outputs does have\n",
    "one complication we didn't see before.  We\n",
    "need to specify different loss functions for the\n",
    "the different output \"heads\" of the network:\n",
    "for instance, age prediction is scalar\n",
    "regression, but gender prediction is a binary\n",
    "classification task and we have split\n",
    "income into 10 levels, so it is a multi-category\n",
    "classification task.  These require different\n",
    "loss functions.  \n",
    "\n",
    "Gradient descent requires us to minimize a\n",
    "single scalar value, so we must combine these\n",
    "losses into a single value in order to train\n",
    "the model.  The simplest way is to sum them all.\n",
    "In Keras, you can use either a list or a dictionary\n",
    "of losses in `compile` to specify different\n",
    "objects for different outputs; the resulting\n",
    "loss values are summed into a global loss, which\n",
    "is minimized during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again example of using a list\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if you name output layers, can be more\n",
    "# precise and use an explicit mapping with a dict\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that very imbalanced loss contributions will cause\n",
    "the model to optimize the parts with the higher\n",
    "loss preferentially, at the expense of the other\n",
    "tasks.  To remedy, we can assign different levels\n",
    "of importance to the loss values in their contribution\n",
    "to the final loss.  This is especially useful\n",
    "if losses are using different scales, for example\n",
    "MSE for age-regression tasks usually has values around\n",
    "3-5, whereas the cross-entropy loss used for\n",
    "gender-classification task can be as low as 0.1.\n",
    "\n",
    "In such a situation, to balance, you can assign a weight of 10 to the crossentropy loss and a weight\n",
    "of 0.25 to the MSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1.0, 10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if you name output layers, can be more\n",
    "# precise and use an explicit mapping with a dict\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.0,\n",
    "                            'gender': 10.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with multi-inputs, you can pass NumPy data to\n",
    "the model for training either via a list of\n",
    "arrays or via a dictionary of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create some dummy data as before \n",
    "# if want to fit the multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "#          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(posts,\n",
    "#          {'age': age_targets,\n",
    "#           'income': income_targets],\n",
    "#           'gender': gender_targets},\n",
    "#          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4 Directed acylic graphs of layers\n",
    "\n",
    "We can use the functional API to build\n",
    "more complex arbitrary *directed acylic graphs*\n",
    "of layers. The qualifier *acylic* is important:\n",
    "the graphs can't have cycles.  The only\n",
    "processing *loops* that are allowed are those\n",
    "internal to recurrent layers.\n",
    "\n",
    "**Inception Modules**\n",
    "\n",
    "This is a layer that itself looks like a small\n",
    "stack of parallel branches.  \n",
    "\n",
    "(Figure 7.8)\n",
    "\n",
    "Here is an implementation by hand of the Inception\n",
    "module shown in figure 7.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4D tensor named x for input of correct shape\n",
    "#x = Input(shape=(100,100,100))\n",
    "\n",
    "# every branch has the same stride value (2),\n",
    "# which is necessary to keep all branch outputs\n",
    "# the same size\n",
    "branch_a = layers.Conv2D(128, 1,\n",
    "                         activation='relu', strides=2)(x)\n",
    "\n",
    "# in this branch, the striding occurs in the spatial convolution layer\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "# in this branch, the striding occurs in the average pooling layer\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "# here stride occurs again in the last spatial\n",
    "# convolution layer\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# concatenates the branch outputs to obtain the module output\n",
    "output = layers.concatenate(\n",
    "    [branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the full Inception V3 architecture is \n",
    "available in Keras as `keras.applications.inception_v3.InceptionV3`\n",
    "including weights pretrained on the ImageNet dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual Connections**\n",
    "\n",
    "*Residual connections* are a common graph-like\n",
    "network component found in many post 2015 \n",
    "network architectures.  \n",
    "\n",
    "They tackle two common problems that plague any\n",
    "large-scale deep-learning model:\n",
    "vanishing gradients and representational\n",
    "bottlenecks.\n",
    "\n",
    "In general, adding residual connections to any\n",
    "model that has more than 10 layers is likely to be\n",
    "beneficial.\n",
    "\n",
    "At it simplest, a residual connection is simply \n",
    "connecting the otuput of an earlier layer to\n",
    "a later layer.  Rather than being concatenated, the\n",
    "earlier output is summed with the later activation.\n",
    "This implies that both activations have to be\n",
    "the same size.  If they're different, you can\n",
    "use a linear transformation to reshape the\n",
    "earlier activation into the target shape.\n",
    "\n",
    "Here's an example of implementing a esidual connection\n",
    "in Keras when the feature-map sizes are the same, using identity residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4D tensor\n",
    "# x = ...\n",
    "\n",
    "# applies transformation to x\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "# adds the original x back to the output features\n",
    "y = layers.add([y, x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following implements a residual connection\n",
    "when the feature-map sizes are different, using a\n",
    "linear residual connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4D tensor\n",
    "# x = ....\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# uses a 1x2 convolution to linearly downsample the\n",
    "# original x tensor to the same shape as y\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "# adds the residual tensor back to the output features\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 Layer weight sharing\n",
    "\n",
    "One more useful feature of the functional API\n",
    "is the ability to reuse a layer instance several\n",
    "times.  When you call a layer instance twice, it\n",
    "reuses the same weights.  You can build models\n",
    "with several branches, all sharing the same\n",
    "knowledge.\n",
    "\n",
    "For example, consider input from two cameras,\n",
    "binocular vision set a few inches apart.  The\n",
    "two streams need to perform basically the same task,\n",
    "so it is much better to train a common set of weights.\n",
    "\n",
    "Or consider a model that measuers semantic\n",
    "similarity between two sentences.  The model\n",
    "has two input sentences (the two sentences to\n",
    "compare).  The model outputs a (probability)\n",
    "score between 0 and 1, where 0 means unrelated, and\n",
    "1 means the same sentence (or a rewording).\n",
    "\n",
    "In this setup the two input sentences are interchangeable,\n",
    "because semantic similarity is a symmetrical\n",
    "relationship: the similarity of A to B is identical\n",
    "to the similarity of B to A.\n",
    "\n",
    "We want to process a single LSTM later, but using\n",
    "two streams for two separate input sentences.\n",
    "\n",
    "Here is an example using Keras functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create left_data and right_data dummy data\n",
    "# for example training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiat single LSTM layer\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# build left branch, inputs are varibale-length\n",
    "# sequences of vectors of size 128\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# build the right branch, here is example of\n",
    "# reusing existing lsm layer again\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# builds a classifier on top\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating and training the model\n",
    "# when you train, the weights of the LSTM layer are\n",
    "# updated based on both inputs\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6 Models as layers\n",
    "\n",
    "It is also useful to know that in Keras, a `Model`\n",
    "can be used as a `layer`.  You can effectively\n",
    "think of a `Model` as encapsulating several layers\n",
    "into a conceptuall single layer, that takes an\n",
    "input tensor and produces and output tensor.\n",
    "\n",
    "This means you can call a model on an input \n",
    "tensor and retrieve an output tensor (i.e.\n",
    "it performs a forward pass on the input\n",
    "batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is multi-input and/or multi-output, you\n",
    "should call it with a list of tensors, and it will\n",
    "return a list/tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = model([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of reusing a model instance\n",
    "is in the vision example we mentioned.  A dual\n",
    "camera setup with two parallel cameras, a few\n",
    "centimeters apart.  \n",
    "\n",
    "Here is an example implementation of a Siamese vision \n",
    "model wiht a shared convolutional base built\n",
    "in Keras (using Xception model/layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the base image-processing model is the Xception network\n",
    "# (convolutional base only)\n",
    "xception_base = applications.Xception(weights=None,\n",
    "                                     include_top=False)\n",
    "\n",
    "# the inputs are 250 x 250 RGB images\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# calls the same vision model twice\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "# the merged features contain information from\n",
    "# the right and left visual fields\n",
    "merged_features = layers.concatenate(\n",
    " [left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7 Wrapping up\n",
    "\n",
    "- You can use Keras functional API when you need\n",
    "  multi-input, multi-output, or more complext\n",
    "  directed acylic graph-like networks.\n",
    "- multi-input and/or multi-output models will usually\n",
    "  outperform building separate networks, training them\n",
    "  in isolation, then combining the results.\n",
    "- You can reuse weights of a layer or even a model\n",
    "  (a collection of layers).  This is useful to\n",
    "  reuse knowledge in several parallel streams in many\n",
    "  types of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\n",
    "\n",
    "We can use callbacks to gain greater control over\n",
    "what goes on during training.  We can get greater\n",
    "insights into what is being learned using TensorBoard\n",
    "visualization tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Using callbacks to act on a model during training\n",
    "\n",
    "We have mostly been using a simple fixed number of epochs for training.  But when training, there are many things we don't know.  How many epochs will we\n",
    "need to get an optimal validation loss, for example.\n",
    "\n",
    "We have used approach to first train and see what epoch model overfits, then train again only for\n",
    "that number of epochs.  This is an example of\n",
    "fixed training epochs schedule.\n",
    "\n",
    "A much better way to handle this is to stop training\n",
    "when you measure that the validation loss is no\n",
    "longer improving (for some value of \"no longer improving\").\n",
    "This can be achieved using a Keras callback.\n",
    "A *callback* is an object that is passed to the\n",
    "model in the call to `fit` and that is called by\n",
    "the model at various points during training.\n",
    "It has access to the available about the state\n",
    "of the model and its performance.  And it can\n",
    "take action: interupt training, save a model,\n",
    "load a different weights, or otherwise alter the\n",
    "state of the model.\n",
    "\n",
    "Here are some examples of ways you can use callbacks:\n",
    "- *Model checkpointing* - Saving the current weights\n",
    "  of the model at different points during training.\n",
    "- *Early stopping* - Interrupting training when the\n",
    "  validation loss is no longer improving.\n",
    "- *Dynamically adjusting the value of certain parameters during training* - such as the learning rate of the optimizer.\n",
    "- *Logging training and validaiton metrics during training, or visualizing the representations learned by the model as they're updated* - The Keras progress bars is a callback, but you can do more.\n",
    "\n",
    "The `keras.callbacks` module includes a number of\n",
    "built-in (predefined) callbacks:\n",
    "\n",
    "- `keras.callbacks.ModelCheckpoint`\n",
    "- `keras.callbacks.EarlyStopping`\n",
    "- `keras.callbacks.LearningRateScheduler`\n",
    "- `keras.callbacks.ReduceLROnPlateau`\n",
    "- `keras.callbacks.CSVLogger`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ModelCheckpoint and EarlyStopping Callbacks**\n",
    "\n",
    "You can use `EarlyStopping` callback to interrupt\n",
    "training once a target metric has stopped improving\n",
    "for a fixed number of epochs.\n",
    "\n",
    "This callback is typically used in combination with \n",
    "`ModelCheckpoint`, which lets you continually\n",
    "save the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    # interrupts training when improvement stops\n",
    "    keras.callbacks.EarlyStopping(\n",
    "       monitor='acc', # monitors model accuracy\n",
    "       patience=1, # stops when accuracy stops improving for more than 1 epoch (e.g. 2 epochs)\n",
    "    ),\n",
    "    \n",
    "    # saves the current weights after every epochs\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5', # path to destination model file\n",
    "        monitor='val_loss', # only keep best model\n",
    "        save_best_only=True, # and best means when the validation_loss improves\n",
    "    )\n",
    "]\n",
    "\n",
    "# monitor accuracy, so it is pat of metrics\n",
    "# (this is needed because we use for EarlyStopping)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# need to provide validation data because we use\n",
    "# validation loss in the example for model checkpointing\n",
    "model.fit(x, y,\n",
    "          epochs=10, # will stop at 10 epochs if we don't stop early\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReduceLROnPlateu Callback**\n",
    "\n",
    "You can use this callback to reduce the lr when\n",
    "the validation loss has stopped improving.  \n",
    "\n",
    "Reducing or increasing lr when loss stops\n",
    "improving (a *loss plateau*) is\n",
    "an effective strategy to get out of local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', # monitor the model validation loss\n",
    "        factor=0.1, # multiplies lr by 0.1 when triggered\n",
    "        patience=10, # only trigger when validation loss stops improving for 10 epochs\n",
    "    )\n",
    "]\n",
    "\n",
    "# again we are monitoring validation loss in the callback\n",
    "# so we need to pass in validation data so it can be computed\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing your own Callback**\n",
    "\n",
    "You can write you own specialized callback.\n",
    "Callbacks are implemented by simply \n",
    "subclassing the base class `keras.callbacks.Callback`.\n",
    "You can then implement any of the following\n",
    "functions, which are called during training:\n",
    "\n",
    "- on_epoch_begin()\n",
    "- on_epoch_end()\n",
    "- on_batch_begin()\n",
    "- on_batch_end()\n",
    "- on_train_begin()\n",
    "- on_train_end()\n",
    "\n",
    "These methods are called with a `logs` argument,\n",
    "which is a dictionary containing information about\n",
    "the previous batch, epoch or training run.\n",
    "In addition, since the callback is a class, there are\n",
    "several attributes that are accessible including:\n",
    "\n",
    "- `self.model` - the model instance being fit/trained\n",
    "- `self.validation_data` - The value of was passed to `fit` as validation data\n",
    "\n",
    "Here is a simple example.  This save to disk\n",
    "the activations of every layer at the end\n",
    "of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we subclass the base class keras.callbacks.Callback\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    # called by parent model before training\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        # model instance that returns the activations of every layer\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs)\n",
    "        \n",
    "    # called at end of each epoch, duh\n",
    "    # we want to save activations of all layers\n",
    "    # at end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "            \n",
    "        # obtain the first input sample of the validation data\n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        \n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        \n",
    "        # save arrays to disk\n",
    "        f = open('activations_at_epoch' + str(epoch) + '.npz', 'w')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2.2 Introduction to TensorBoard: the TensorFlow visualization framework\n",
    "\n",
    "If you are working on tough or cuting edge problems,\n",
    "you need to know how to do \"experiments\" on your\n",
    "model, to understand and visualize what is going\n",
    "on and to understand how it is performing its\n",
    "work.\n",
    "\n",
    "Making progress (like experimental science) is\n",
    "an iterative process.  You start with an idea,\n",
    "formulate a hypothesis, design an experiment to\n",
    "test the hypothesis, and run it to validate or\n",
    "invalidate your idea.\n",
    "\n",
    "The key purpose of TensorBoard is to help you\n",
    "visually monitor everything that goes on inside\n",
    "of your model during training.  TensorBoard\n",
    "is browser based.  It gives you access to:\n",
    "\n",
    "- Visually monitoring metrics during training\n",
    "- Visualizing your model architecture\n",
    "- Visualizing histograms of activations and\n",
    "  gradients\n",
    "- Exploring embeddings in 3D\n",
    "  \n",
    "  \n",
    "Let's demonstrate on a simple example.  You'll train\n",
    "a 1D convnet on the IMDB sentiment-analysis task.\n",
    "We consider only the top 2,000 words in the IMDB\n",
    "vocabulary, to make visualizing word embeddings\n",
    "more tractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbe rof words to consider as features\n",
    "max_features = 2000\n",
    "# cuts off texts after this number of words\n",
    "max_len = 500\n",
    "\n",
    "# load the imdb data\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "            input_length=max_len,\n",
    "            name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: I created a directory called logfiles\n",
    "one level up from the current directory, to\n",
    "hold the TensorFlow logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='../logfiles',\n",
    "        histogram_freq=1, # records activation histogram every 1 epoch\n",
    "        embeddings_freq=1, # records embedding data every 1 epoch\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the tensorboard server, while training is\n",
    "occurring:\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=logfiles\n",
    "```\n",
    "\n",
    "The graphs show all of the actual tensorflow\n",
    "structures/layers that were created from the \n",
    "high-level Keras API.  Keras also provides\n",
    "a cleaner way to plot models as graphs of\n",
    "layers, rather than graphs of tensorflow\n",
    "operations, the `keras.utils.plot_model` utility.\n",
    "This may not work unless you have Python `pydot`\n",
    "and `pydot-ng` libraries installed, as well\n",
    "as the `graphviz` library.\n",
    "\n",
    "(Try using conda install for pydot and graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='figures/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/model.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='figures/model-shapes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/model-shapes.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Wrapping up\n",
    "\n",
    "- Keras callbacks allow you to monitor models during\n",
    "  training and automatically take actions to stop or\n",
    "  modify training parameters while learning.\n",
    "- When using TensorFlow backend, can use TensorBoard\n",
    "  built in tool to visualize model activity in\n",
    "  browser (TensorBoard callback in Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the most out of your models\n",
    "Most materials up to this point have been helping\n",
    "you to build basic intutions on what works, to begin\n",
    "specifying hyperparameters and model architectures.\n",
    "This section has some discussions of newer promising\n",
    "trends.\n",
    "\n",
    "### 7.3.1 Advanced architecture patterns\n",
    "\n",
    "Residual connections, covered in 7.1, are one \n",
    "example of advanced architecture patterns to keep\n",
    "in mind.\n",
    "\n",
    "**Batch Normalization**\n",
    "\n",
    "Another is *batch normalization*.  You are familiar\n",
    "with normalization techniques.  We have always, to\n",
    "this point, exhorted you to normalize your data.\n",
    "We have always normalized the data in preprocessing,\n",
    "before using it for training in a DNN.\n",
    "\n",
    "But even if data entering a network has been\n",
    "normalized, there is no guarantee, given the\n",
    "current settings of the weights of the layer, that\n",
    "the output tensors will also be normalized.  \n",
    "And this can again be a problem.  For the same reason\n",
    "we have been normalizing data before training with it\n",
    "if data tensors output from layers have values that\n",
    "are of different scales or large ranges, it can make\n",
    "it more difficult for the layer to learn.\n",
    "\n",
    "Batch normalization is a type of layer \n",
    "(`BatchNormalization` in Keras) that can\n",
    "adaptively normalize data, even as the mean and\n",
    "variance change over time during training.  Basically\n",
    "it does the same thing we did by hand, to compute\n",
    "values to shift the mean to 0 and scale the\n",
    "variance to have a standard deviation of 1.  But\n",
    "since the mean and variance can and will change\n",
    "during training, the batch normalization layer\n",
    "maintains an exponentialy weighted moving\n",
    "set of parameter to shift and rotate the output.\n",
    "It learns these parameters at the same time that\n",
    "gradient descent learning occurs.  \n",
    "\n",
    "The main effect of batch normalization is that it\n",
    "helps with gradient propagation.  By normalizing\n",
    "outputs, it again ensures that signals of the\n",
    "gradients are more properly preserved.  Thus it is\n",
    "also a technique for addressing vanishing gradients\n",
    "problems.  Thus batch normalization allows\n",
    "for deeper networks to be created and trained\n",
    "effectively.\n",
    "\n",
    "The `BatchNormalization` layer is typically\n",
    "used after a convolutional or densely connected\n",
    "layer.  You can have multiple `BatchNormalization`\n",
    "layers in a network.  It doesn't make sense to\n",
    "put batch layer everywhere, like after maxpooling\n",
    "layers.  It is less clear whether these can be\n",
    "useful after recurrent layers (it will depend on\n",
    "the sequence/series data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after a conv layer\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_mode.add(layers.BatchNormalization())\n",
    "\n",
    "# after a Dense layer\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BatchNormalization` layer takes an `axis`\n",
    "argument, which specifies the feature axis that\n",
    "should be normalized.  The default is -1 (which\n",
    "optimizes the last feature axis from the layer).\n",
    "This is correct for `Dense` layers, `Conv1D` and\n",
    "`Conv2D` when the channels are last.  When\n",
    "channels are first in a `Conv2D` you should set\n",
    "the `axis` to 1.\n",
    "\n",
    "*Batch renormalization* is a recent improvement\n",
    "to be aware of, from original designers of\n",
    "batch normalization, that may become common and\n",
    "replace batch normalization.  It appears to\n",
    "be clearly a bit better, with no apparent cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depthwise Separable Convolution**\n",
    "\n",
    "A drop-in replacement for `Conv2D` that has fewer\n",
    "trainable parameters, and is faster, and usually\n",
    "performs better than a simple `Conv2D`.  \n",
    "\n",
    "It is an acylic directed graph.  Each channel\n",
    "is handled in parallel using a convolution, which\n",
    "is concatenated and then processed through a\n",
    "1x1 pointwise convolution (Figure 7.16).\n",
    "\n",
    "May be especially advantegous for small models\n",
    "on limited data (either image classification\n",
    "or using convolutions for natural language sequences).\n",
    "\n",
    "An example of an image-classification networks\n",
    "using softmax categorical classification with \n",
    "these separable convnets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Modle\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,\n",
    "                                activation='relu',\n",
    "                                input_shape=(height, width, channels)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='cattegorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separable convolutions are also used heavily in\n",
    "more recent larger models, like Xception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Hyperparameter optimization\n",
    "\n",
    "When you do ML long enough, you build up intuition\n",
    "on good hyperparameters to approach building\n",
    "architectures for different types of tasks.\n",
    "But your initial settings are almost certianly not\n",
    "going to be optimal.  We can iterate by hand,\n",
    "exploring the hyperparameter space.\n",
    "But, there is no good principled way to\n",
    "explore the hyperparameter space (unlike the\n",
    "normal weight/parameter space), because:\n",
    "\n",
    "- Computing the feedback signal can be extremely\n",
    "  expensive (imagine training a ResNet from scratch\n",
    "  to explore different number of layers or lr settings).\n",
    "- The hyperparameter space is discrete.  Not being\n",
    "  continuous, we can't do gradient descent optimization\n",
    "  on the hyperparamters.  Must rely on gradient-free\n",
    "  optimization techniques.\n",
    "  \n",
    "Random (covering space, and informed) search still\n",
    "often the best.\n",
    "\n",
    "Tools to try out, if you have a cluster and need to\n",
    "really methodically explore a hyperparameter\n",
    "space for a network: Hyperopt using Python fo\n",
    "hyperparameter optimization in general, and\n",
    "Hyperas (Hyperopt for Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 Model ensembling\n",
    "\n",
    "Ensembling consists of pooling together the\n",
    "predictions of a set of different models, to\n",
    "produce better predictions.\n",
    "\n",
    "Assumes different models trained independently are\n",
    "likely to be good for *different reasons*.\n",
    "\n",
    "When combining models, can take the simple average.\n",
    "For example, if have 4 softmax classifiers, could\n",
    "add and take average of predictions to get\n",
    "'ensembled' predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only works if all 4 classifiers are more or less\n",
    "equally good.\n",
    "\n",
    "If not, use a weighted average.  For example,\n",
    "this could be a ML/optimization task, to determine\n",
    "the optimal weights for an ensemble of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emphasize, goal is ensemble models are *as good\n",
    "as possible* while being *as different as possible*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4 Wrapping up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
